{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "import time\n",
    "import glob as glob\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitch API\n",
    "\n",
    "Objective: \n",
    "- leverage Twitch's API to request 2019-2020 data. \n",
    "\n",
    "Purpose: \n",
    "- Twitch is a market leader in sVoD. I want to include them in my \"Streaming Amid Pandemic\" analysis.\n",
    "\n",
    "Endpoints: \n",
    "- user subscriptions\n",
    "- top streams\n",
    "- time watched\n",
    "- top titles watched by week\n",
    "- top 10 genres\n",
    "- top 10 titles by genre\n",
    "\n",
    "Steps: \n",
    "- register for api \n",
    "- authenticate \n",
    "- access\n",
    "- call API for endpoints above\n",
    "- don't forget function\n",
    "- execute initial eda in python\n",
    "- ship csv for tidy eda\n",
    "- mvp the twitch tableau dashboard\n",
    "\n",
    "Documentation:\n",
    "- https://dev.twitch.tv/docs/\n",
    "- https://oauth.net/2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#testing api\n",
    "\n",
    "top_games_df='https://api.twitch.tv/helix/games/top'\n",
    "result=requests.get(top_games_df)\n",
    "result.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" GET https://id.twitch.tv/oauth2/authorize\n",
    "    ?client_id='***'\n",
    "    &redirect_uri='*****'\n",
    "    &response_type=client_id\n",
    "    &scope=<space-separated list of scopes>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(access_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_code.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access token\n",
    "\n",
    "token = json.loads(access_code.text)\n",
    "access_token = token['access_token']\n",
    "\n",
    "'''\n",
    "\n",
    "sample response:\n",
    "\n",
    "{\n",
    "  \"access_token\": \"****\",\n",
    "  \"refresh_token\": \"\",\n",
    "  \"expires_in\": 3600,\n",
    "  \"scope\": [],\n",
    "  \"token_type\": \"bearer\"\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "#curl -H 'Client-ID: *****' \\\n",
    "#-H 'Authorization: Bearer *****' \\\n",
    "#-X GET 'https://api.twitch.tv/helix/games/top'\n",
    "\n",
    "This might be the wrong direction. I think it's more for users you want to authenticate to your registered redirect URI.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "POST https://id.twitch.tv/oauth2/token\n",
    "    ?client_id='***'\n",
    "    &client_secret='****'\n",
    "    &grant_type=client_credentials\n",
    "    &scope='top-games'\n",
    "\n",
    "'''\n",
    "\n",
    "#OAuth issuse...come back to this after class is out to fix api, use csvs for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivoting to csvs \n",
    "- timeframe: 2016-2020\n",
    "- compile into dfs for games and channels\n",
    "- extent: top 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_streamed_df = pd.read_csv('../data/twitch_most_streamed.csv')\n",
    "most_streamed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_streamed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping unnamed \n",
    "most_streamed_df = most_streamed_df.loc[:, ~most_streamed_df.columns.str.contains('^Unnamed')]\n",
    "most_streamed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_watched_df = pd.read_csv('../data/twitch_most_watched.csv')\n",
    "most_watched_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "most_watched_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnamed \n",
    "most_watched_df = most_watched_df.loc[:, ~most_watched_df.columns.str.contains('^Unnamed')]\n",
    "most_watched_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "largest_viewership_df = pd.read_csv('../data/twitch_largest_peak_viewership_year.csv')\n",
    "largest_viewership_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_viewership_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnamed \n",
    "largest_viewership_df = largest_viewership_df.loc[:, ~largest_viewership_df.columns.str.contains('^Unnamed')]\n",
    "largest_viewership_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "peak_viewership_df = pd.read_csv('../data/twitch_peaks.csv')\n",
    "peak_viewership_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_viewership_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unnamed \n",
    "peak_viewership_df = peak_viewership_df.loc[:, ~peak_viewership_df.columns.str.contains('^Unnamed')]\n",
    "peak_viewership_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Just use the frist csv. Don't need bottom three to do further analysis, python can handle it via first one. Must have exported redunant csvs or renamed wrong upon initial inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizulaization idea: Possibly an animation showing viewers engagement over time? Something like... 50 most watched channels by week for q4 2019 through q1 2020. (the first figure here might be a good direction: https://www.tableau.com/about/blog/2020/2/bring-your-data-life-viz-animations). Use bubble size to indicate follower gain and viewership over 7 day rolling averages. y-axis = viewer count average by week. x-axis = followers per month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitch_concat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update: scratch that above. bring all dfs together for channels and games. Could probably run a generator expression and add date year month columns, ie:\n",
    "\n",
    "### pd.concat((pd.read_csv(file).assign(filename = stats)\n",
    "### for stats in stats_2020), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "#method 2 \n",
    "#making a concatination function to multiple csv files into one csv. try this for channels and games folders of months 2016-2020, should be 106 csvs.\n",
    "\n",
    "def concatenate(indir=\"/Users/home/Desktop/nss_data_analytics/capstone/streaming_analysis_amid_pandemic/data/narrowed/twitch/stats/2020\",outfile=\"/Users/home/Desktop/nss_data_analytics/capstone/streaming_analysis_amid_pandemic/data/tidy/twitch/concatenated.csv\"):\n",
    "    os.chdir(indir)\n",
    "    fileList=glob.glob(\"*.csv\")\n",
    "    dfList=[]\n",
    "    colnames=[\"name\",\n",
    "              \"rank\",\n",
    "              \"game\",\n",
    "              \"watch_time\",\n",
    "              \"stream_time\",\n",
    "              \"peak_viewers\",\n",
    "              \"peak_channels\",\n",
    "              \"streamers\",\n",
    "              \"average_viewers\",\n",
    "              \"average_channels\",\n",
    "              \"average_viewer_ratio\",\n",
    "              \"name\"]\n",
    "    \n",
    "    #looping\n",
    "    for filname in fileList:\n",
    "        print(filname)\n",
    "        df=pandas.read_csv(filename,header=None)\n",
    "        dfList.append(df)\n",
    "    concatDf=pandasdas.concat(dfList,axis=0)\n",
    "    concatDf.columns=colnames\n",
    "    concat.to_csv(outfile,index=None)\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
